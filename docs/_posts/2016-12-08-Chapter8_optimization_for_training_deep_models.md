---ntitle: 深度模型中的优化nlayout: postnshare: falsen---
深度学习算法在许多情况下都涉及到优化。
例如，模型中的推断（如PCA）涉及到求解优化问题。
我们经常使用解析优化去证明或设计算法。
在深度学习涉及到诸多优化问题中，最难的是神经网络训练。
甚至是用几百台机器投入几天到几个月去解决一个神经网络训练问题，也是很常见的。
因为这其中的优化问题很重要，代价也很高，因此开发了一组专门的优化技术。
本章会介绍神经网络训练中的这些优化技术。

如果你不熟悉基于梯度的基本优化，我们建议您查看\chap?。
该章简要概述了一般的数值优化。

本章主要关注这一类优化问题：寻找神经网络上的一组参数$\Vtheta$以显著降低代价函数 $J(\Vtheta)$，该代价函数通常包括整个训练集上的性能评估和正则项。

首先，我们会介绍机器学习任务训练算法中的优化和纯优化在哪些地方不一样。
接下来，我们会介绍神经网络优化很难的几个具体原因。
然后，我们会介绍几个实用算法，包括优化算法本身和初始化参数的策略。
更高级的算法能够在训练中调整学习速率，或者使用代价函数二阶导数包含的信息。
最后，我们会介绍几个将简单优化算法融入高级过程的优化策略。

<!-- % -- 267 -- -->

n# 学习和纯优化有什么不同n
用于深度模型训练的优化算法与传统的优化算法在几个方面有所不同。
机器学习通常是间接的。
在大多数机器学习问题中，我们关注定义于测试集上的，也可能是不可解的性能度量$P$.
因此，我们只是间接地优化$P$。
我们希望通过降低代价函数 $J(\Vtheta)$来提高$P$。
这一点不同于纯优化最小化$J$本身。
训练深度模型的优化算法通常也会包括一些用于机器学习目标函数特定结构上的特殊优化。

通常，代价函数可写为训练集上的平均，如
\begin{equation}
    J(\Vtheta) = \SetE_{(\RVx, \RSy) \sim\hat{p}_\text{data}} L(f(\Vx ; \Vtheta), y),
\end{equation}
其中$L$是每个样本的损失函数，$f(\Vx;\Vtheta)$是输入是$\Vx$时的预测输出，$\hat{p}_{\text{data}}$是经验分布。
监督学习中，$y$是目标输出。
在本章中，我们会介绍不带正则项的监督学习，$L$的参数是$f(\Vx;\Vtheta)$和$y$。
很容易将这种监督学习扩展成其他形式，如包括$\Vtheta$或者$\Vx$做参数，或是去掉参数$y$，以发展不同形式的正则项或是无监督学习。

\eqn?定义了训练集上的目标函数。
通常，我们更希望最小化期望取自\emph{数据生成分布}$p_{\text{data}}$而不仅是有限个训练集上的对应目标函数：
\begin{equation}
    J^*(\Vtheta) = \SetE_{(\RVx, \RSy) \sim p_\text{data}} L(f(\Vx ;\Vtheta),y).
\end{equation}

n## 经验风险最小化n
机器学习算法的目标是降低\eqn?所示的期望泛化误差。
这个数据量被称为风险。
值得注意的是，该期望取自真实的数据分布$p_\text{data}$。
如果我们知道了真实分布$p_\text{data}(\Vx, y)$，那么最小化风险变成了一个优化问题。
然而，我们遇到的机器学习问题，通常是不知道$p_\text{data}(\Vx, y)$，只知道训练集中的样本。

<!-- % -- 268 -- -->

将机器学习问题转化成优化问题的最简单方法是最小化训练集上的期望损失。
这意味着用训练集上的经验分布$\hat{p}(\Vx,y)$替代真实分布$p(\Vx,y)$。
如此，我们将最小化经验风险：
\begin{equation}
    \SetE_{\RVx, \RSy \sim \hat{p}_\text{data}} [L(f(\Vx ; \Vtheta), y)]
    = \frac{1}{m} \sum_{i=1}^m L( f(\Vx^{(i)}; \Vtheta), y^{(i)}) ,
\end{equation}
其中$m$表示训练样本的数目。

基于最小化如上平均训练误差的训练过程被称为经验风险最小化。
在这种情况下，机器学习仍然和传统的直接优化很相似。
并非直接最优化风险，我们最优化经验风险，希望也能够很大地降低风险。
一系列不同的理论表明，在不同条件下，真实风险的期望可以下降不同的量。

然而，经验风险最小化容易过拟合。
高容量的模型会简单地记住训练集。
在很多情况下，经验风险最小化并非真的可行。
最有效的现代优化算法是基于梯度下降的，但是很多有用的损失函数，如$0-1$损失，没有导数（导数要么为零，要么没有定义）。
这两个问题说明，在深度学习中我们很少使用经验风险最小化。
反之，我们会使用一个稍稍不同的方法，我们真正优化的目标会更加不同于我们希望优化的目标。

n## 替代损失函数和提前终止n
有时，我们真正关心的损失函数（比如分类误差）并不能有效地优化。
例如，即使对于线性分类器而言，精确地最小化$0-1$损失通常是不可解的（复杂度几何级数增长于输入维数）{cite?}。
在这种情况下，我们通常会优化替代损失函数。
替代损失函数作为原目标的代理，还有一些优点。  
例如，正确类别的负对数似然通常用作$0-1$损失的替代。
负对数似然允许模型估计给定样本的条件概率，如果该模型效果好，那么它能够输出最小期望分类误差对应的类别。

<!-- % -- 269 -- -->

在某些情况下，替代损失函数能比原函数学习到更多。
例如，使用对数似然替代函数时，在训练集上的$0-1$损失达到$0$之后，测试集上的$0-1$损失还能持续下降很长一段时间。
这是因为即使$0-1$损失期望是零时，我们还能拉开不同类别的距离以改进分类器的鲁棒性，获得一个更强壮的，值得信赖的分类器。
因而，相较于简单地最小化训练集上的平均$0-1$损失，从训练数据中抽取了更多信息。

一般的优化和我们用于训练算法的优化的一个重要不同：训练算法通常不收敛在局部极小。
反之，机器学习通常优化替代损失函数，并可能基于\sec?的收敛条件提前终止。
通常，提前终止使用真实损失函数，如验证集上的$0-1$损失函数，并在过拟合发生之前终止；与纯优化不同的是，提前终止时替代损失函数仍然有较大的导数，而纯优化终止时导数较小。

n## 批算法和minibatch算法n
机器学习算法和一般优化算法不同的一点是，机器学习算法的目标函数通常可以分解为训练样本上的求和。
机器学习优化算法通常使用整个代价函数中的一部分项去更新其参数。

例如，最大似然估计问题可以在对数空间中分解成每个样本的总和：
\begin{equation}
    \Vtheta_{\text{ML}} = \underset{\Vtheta}{\argmax} \sum_{i=1}^m
    \log p_{\text{model}} (\Vx^{(i)}, y^{(i)}; \Vtheta) .
\end{equation}

最大化这个总和等价于最大化训练集在经验分布上的期望：
\begin{equation}
    J(\Vtheta) = \SetE_{\RVx, \RSy \sim\hat{p}_\text{data}} 
    \log p_{\text{model}} (\Vx,y ; \Vtheta) .
\end{equation}

<!-- % -- 270 -- -->

优化算法用到的目标函数$J$中的大多数性质也是训练集上的期望。
例如，最常用的性质是导数：
\begin{equation}
    \nabla_{\Vtheta} J(\Vtheta) = \SetE_{\RVx, \RSy \sim\hat{p}_{\text{data}}} 
    \nabla_{\Vtheta} \log p_{\text{model}} (\Vx,y; \Vtheta) .
\end{equation}

准确计算这个期望的计算量非常大，因为需要计算整个数据集上的每个样本。
在实践中，我们可以从数据集中随机采样少量的样本，然后计算这些样本上的平均值。

回想一下，$n$个样本的均值标准误差（\eqn?）是$\sigma/\sqrt{n}$，其中$\sigma$是样本值真实的标准差。
分母$\sqrt{n}$表明使用更多样本来估计梯度的方法的回报是低于线性的。
比较两个假想的梯度计算，一个基于$100$个样本，另一个基于$10,000$个样本。
后者的计算量多于前者的$100$倍，但却只降低了$10$倍的标准差。
如果能够快速计算出梯度估计值，而不是缓慢计算准确值，那么大多数优化算法会收敛地更快（就总的计算量而言，而不是指更新次数）。

另一个从小数目样本中估计梯度的动机是训练集的冗余。
在最坏的情况下，训练集合中所有的$m$个样本可以是彼此相同的拷贝。
基于采样的梯度估计可以使用单个样本计算出正确的梯度，而比原来的做法少花了$m$倍时间。
实践中，我们不太可能真的遇到这种最坏情况，但我们可能会发现大量样本都对梯度做出了非常相似的贡献。

使用整个训练集的优化算法被称为batch或确定性梯度算法，因为它们会同时大batch地处理所有的样本。
这个术语可能有点令人困惑，因为这个词"batch"也经常被用来描述minibatch随机梯度下降算法中用到的minibatch样本。
通常，术语"batch梯度下降"指使用全部训练集，而术语"batch"单独出现时指一组样本。
例如，我们普遍使用术语"batch大小"表示minibatch的大小。

每次只使用单个样本的优化算法有时被称为随机或者在线算法。
术语"在线"通常是指从连续产生样本的数据流中抽取样本的情况，而不是从一个固定大小的训练集中遍历多次采样的情况。

<!-- % -- 271 -- -->

大多数用于深学习的算法介于以上两者之间，使用一个以上，而又不是全部的训练样本。
