---ntitle: 机器学习基础nlayout: postnshare: falsen---
深度学习是机器学习的一个特定分支。
要想学好深度学习，必须对机器学习的基本原理有深刻的理解。
本章将探讨贯穿本书其余部分的一些机器学习重要原理。
我们建议新手读者或是希望更全面了解的读者参考一些更全面覆盖基础知识的机器学习参考书，例如{MurphyBook2012}或者{bishop-book2006}。
如果你已经熟知机器学习，可以跳过前面的部分，前往\sec?。
\sec?涵盖了一些传统机器学习技术的观点，这些技术对深度学习的发展有着深远影响。

首先，我们将介绍学习算法的定义，并介绍一个简单的示例：线性回归算法。
接下来，我们会探讨拟合训练数据和寻找能够泛化到新数据的参数有哪些不同。
大部分机器学习算法都有\emph{超参数}（必须在学习算法外设定）；我们将讨论如何使用额外的数据设置超参数。
机器学习本质上属于应用统计学，更多关注于如何用计算机统计地估计复杂函数，不太关注这些函数的置信区间；因此我们会探讨两种统计学的主要方法：频率估计和贝叶斯推断。
大部分机器学习算法可以分成监督学习和无监督学习两类；我们将探讨不同的分类，并为每类提供一些简单的机器学习算法作为示例。
大部分深度学习算法都基于随机梯度下降求解。
我们将介绍如何组合不同的算法部分，例如优化算法、代价函数、模型和数据集，来建立一个机器学习算法。
最后在\sec?，我们会介绍一些限制传统机器学习泛化能力的因素。
这些挑战促进了深度学习的发展，以解决这些问题。

<!-- % -- 95 -- -->

n# 学习算法n
机器学习算法是一种可以从数据中学习的算法。
然而，我们所谓的"学习"是什么意思呢？
{Mitchell:1997:ML}提供了一个简洁的定义："对于某类任务$T$和性能度量 $P$，一个计算机程序被认为可以从经验 $E$中学习是指，通过经验 $E$改进后，它在任务$T$上由性能度量 $P$衡量的性能有所提升。"
经验 $E$，任务$T$和性能度量 $P$的定义范围非常宽广，在本书中我们并不会去试图解释这些定义的具体意义。
相反，我们会在接下来的章节中提供直观的解释和示例来介绍不同的任务、性能度量和经验，这些将被用来构建机器学习算法。

n## 任务 $T$n
机器学习可以让我们解决一些人为设计和实现固定程序很难解决的问题。
从科学和哲学的角度来看，机器学习受到关注是因为发展我们对机器学习的认识需要发展我们对智能背后原理的理解。

如果考虑"任务"比较正式的定义，那么学习的过程并不是任务。
学习是我们所谓的获取完成任务的能力。
例如，我们的目标是会行走的机器人，那么行走便是任务。
我们可以编程让机器人学会如何行走，或者可以编写特定的指令，人工指导机器人如何行走。

通常机器学习任务定义为机器学习系统该如何处理样本。
样本是指我们从某些希望机器学习系统处理的对象或事件中收集到的已经量化的特征的集合。
我们通常会将样本表示成一个向量$\Vx\in\SetR^n$，其中向量的每一个元素$x_i$是一个特征。
例如，一张图片的特征通常是指这张图片的像素。

<!-- % -- 96 -- -->

机器学习可以解决很多类型的任务。
一些非常常见的机器学习任务列举如下：

+ \textbf{分类}：
    在这类任务中，计算机程序需要指定某些输入属于$k$类中的哪一类。
    为了完成这个任务，学习算法通常会返回一个函数$f:\SetR^n \to \{1,\dots,k\}$。
    当$y=f(\Vx)$时，模型为向量$\Vx$所代表的输入指定数字码$y$所代表的类别。
    还有一些其他的分类问题，例如，$f$输出的是不同类别的概率分布。
    分类任务中有一类是对象识别，输入是图片（通常用一组像素亮度值表示），输出是表示图片物体的数字码。
    例如Willow Garage PR2机器人像服务员一样识别不同饮料，并送给点餐的顾客{cite?}。
    目前，最好的对象识别工作正是基于深度学习{cite?}。
    对象识别同时也是计算机识别人脸的基本技术，可用于标记相片集中的人脸{cite?}，有助于计算机更自然地和用户交互。
    
+ \textbf{输入缺失分类}：
    当输入向量的每个度量不被保证的时候，分类问题将会更有挑战。
    为了解决分类任务，学习算法只需要定义\emph{一个}从输入向量映射到输出类别的函数。
    当一些输入可能丢失时，学习算法必须学习\emph{一组}函数，而不是单个分类函数。
    每个函数对应着分类具有不同缺失输入子集的$\Vx$。
    这种情况在医疗诊断中经常出现，因为很多类型的医学测试是昂贵的，对身体有害的。
    有效地定义这样一个大集合函数的方法是学习所有相关变量的概率分布，然后通过边缘化缺失变量来解决分类任务。 
    使用$n$个输入变量，我们现在可以获得每个可能的缺失输入集合所需的所有$2^n$个不同的分类函数，但是计算机程序仅需要学习一个描述联合概率分布的函数。
    参见{Goodfellow-et-al-NIPS2013}了解以这种方式将深度概率模型应用于这样任务的示例。 
    本节中描述的许多其他任务也可以推广到缺失输入的情况; 缺失输入分类只是机器学习能够解决的问题的一个示例。
    
<!-- % -- 97 -- -->

+ \textbf{回归}：这类任务中，计算机程序会给定输入预测数值。
    为了解决这个问题，学习算法会输出函数$f:\SetR^n \to \SetR$。
    除了返回结果的形式不一样外，这类问题和分类问题是很像的。
    这类任务的一个示例是预测投保人的索赔金额（用于设置保险费），或者预测证券未来的价格。
    这类预测也用在算法交易中。
    
+ \textbf{转录}：
    这类任务中，机器学习系统观测一些相对非结构化表示的数据，并转录信息为离散的文本形式。
    例如，光学字符识别要求计算机程序根据文本图片返回文字序列（ASCII码或者Unicode码）。
    谷歌街景以这种方式使用深度学习处理街道编号{cite?}。
    另一个例子是语音识别，计算机程序输入一段音频波形，输出一序列音频记录中所说的字符或单词ID的编码。
    深度学习是现代语音识别系统的重要组成部分，广泛用于各大公司，包括微软，IBM和谷歌{cite?}。

+ \textbf{机器翻译}：在机器翻译任务中，输入是一种语言的符号序列，计算机程序必须将其转化成另一种语言的符号序列。
    这通常适用于自然语言，如将英语译成法语。
    最近，深度学习已经开始在这个任务上产生重要影响{cite?}。

+ \textbf{结构化输出}：结构化输出任务涉及到输出是不同元素之间重要关系的向量（或者是含多个值的其他数据结构）的任务。
    这是一个很大的范畴，包括上面转录任务和翻译任务在内的很多其他任务。
    例如语法分析——映射自然语言句子到语法结构树，并标记树的节点为动词，名词，副词等等。
    参考{Collobert-AISTATS2011}应用深度学习到语法分析。
    另一个例子是图像的像素级分割，将每一个像素分配到特定类别。
    例如，深度学习可用于标注航拍照片中的道路位置{cite?}。
    在这些标注型的任务中，输出的结构形式不需要和输入尽可能相似。
    例如，在图片标题中，计算机程序观察到一幅图，输出描述这幅图的自然语言句子{cite?}。
    这类任务被称为\emph{结构化输出任务}是因为输出值之间内部紧密相关。
    例如，图片标题程序输出的单词必须组合成一个通顺的句子。

<!-- % -- 98 -- -->

+ \textbf{异常检测}：这类任务中，计算机程序在一组事件或对象中筛选，并标记不正常或非典型的个体。
    异常检测任务的一个例子是信用卡欺诈检测。
    通过对你的购买习惯建模，信用卡公司可以检测到你的卡是否被滥用。
    如果窃贼窃取你的信用卡或信用卡信息，窃贼采购物品的分布通常和你的不同。
    当该卡发生了不正常的购买行为时，信用卡公司可以尽快冻结该卡以防欺诈。
    参考{chandola2009anomaly}了解欺诈检测方法。

+ \textbf{合成和采样}：这类任务中，机器学习程序生成一些和训练数据相似的新样本。
    通过机器学习，合成和采样可能在媒体应用中非常有用，可以避免艺术家大量昂贵或者乏味费时的手动工作。
    例如，视频游戏可以自动生成大型物体或风景的纹理，而不是让艺术家手动标记每个像素{cite?}。
    在某些情况下，我们希望采样或合成过程可以根据给定的输入生成一些特定类型的输出。
    例如，在语音合成任务中，我们提供书写的句子，要求程序输出这个句子语音的音频波形。
    这是一类\emph{结构化输出任务}，但是多了每个输入并非只有一个正确输出的条件，我们明确希望输出有很大的偏差，使结果看上去更加自然和真实。

+ \textbf{缺失值填补}：这类任务中，机器学习算法给定一个新样本 $\Vx\in\SetR^n$，$\Vx$中某些元素$x_i$缺失。
    算法必须填补这些缺失值。

<!-- % -- 99 -- -->

+ \textbf{去噪}：这类任务中，机器学习算法的输入是，由未知破坏过程从\emph{干净样本}$\Vx \in \SetR^n$得到的\emph{污染样本}$\tilde{\Vx} \in \SetR^n$。
    算法根据污染后的样本 $\tilde{\Vx}$预测干净的样本 $\Vx$，或者更一般地预测条件概率分布$P(\Vx\mid\tilde{\Vx})$。
    
+ \textbf{密度估计}\textbf{或}\textbf{概率分布律函数估计}：在密度估计问题中，机器学习算法学习函数$p_{\text{model}}:\SetR^n \to \SetR$，其中$p_{\text{model}}(\Vx)$可以解释成样本采样空间的概率密度函数（如果$\RVx$是连续的）或者概率分布律函数（如果$\RVx$是离散的）。
    要做好这样的任务（当我们讨论性能度量 $P$时，我们会明确定义任务是什么），算法需要学习观测到的数据的结构。
    算法必须知道什么情况下样本聚堆出现，什么情况下不太可能出现。
    以上描述的大多数任务都要求学习算法至少能隐式地抓住概率分布的结构。
    密度分布可以让我们显式地抓住该分布。
    原则上，我们可以在该分布上计算以便解决其他任务。
    例如，如果我们通过密度估计得到了概率分布$p(\Vx)$，我们可以用该分布解决缺失值填补任务。
    如果$x_i$的值是缺失的，但是其他的变量值$\Vx_{-i}$已知，那么我们可以得到条件概率分布$p(x_i\mid\Vx_{-i})$。
    现实中，密度估计并非能够解决所有这类问题，因为在很多情况下$p(\Vx)$是难以计算的。


当然，还有很多其他或其他类型的任务。
这里我们列举的任务类型只是用来介绍机器学习可以做哪些任务，并非严格地定义机器学习任务分类。

n## 性能度量 $P$n
为了评估机器学习算法的能力，我们必须设计其性能的定量度量。
通常性能度量 $P$是特定于系统执行的任务$T$而言的。

对于诸如分类，缺失输入分类和转录任务，我们通常度量模型的准确率。
准确率是指该模型输出正确结果的样本比例。
我们也可以通过错误率得到相同的信息。
错误率是指该模型输出错误结果的样本比例。
我们通常把错误率称作$0$-$1$损失的期望。
在一个特定的样本上，如果结果是对的，那么$0$-$1$损失是$0$；否则是$1$。
但是对于密度估计这类任务而言，度量准确率，错误率或者其他类型的$0$-$1$损失是没有意义的。
反之，我们必须使用不同的性能度量，使模型对每个样本都输出一个连续数值的得分。
最常用的方法是输出模型在一些样本上概率对数的平均值。


<!-- % -- 100 -- -->

通常，我们会更加关注机器学习算法在未观测数据上的性能如何，因为这将决定其在现实生活中的性能如何。
因此，我们将训练机器学习系统的训练集数据中的一部分作为测试集数据评估系统性能。

性能度量的选择或许看上去简单且客观，但是选择一个与系统理想表现对应的性能度量通常是很难的。

在某些情况下，这是因为很难决定应该度量什么。
例如，在执行转录任务时，我们是应该度量系统转录整个序列的准确率，还是应该用一个更细粒度的指标，对序列中部分元素正确的以正面评价？
在执行回归任务时，我们应该更多地惩罚频繁犯一些中等错误的系统，还是较少犯错但是犯很大错误的系统？
这些设计的选择取决于应用。

还有一些情况，我们知道应该度量哪些数值，但是度量它们不太现实。
这种情况经常出现在密度估计中。
很多最好的概率模型只能隐式地表示概率分布。
在许多这类模型中，计算空间中特定点的概率是不可行的。
在这些情况下，我们必须设计一个仍然对应于设计对象的替代标准，或者设计一个理想标准的良好近似。

n## 经验 $E$n
根据学习过程中的不同经验，机器学习算法可以大致分类为无监督和监督。

本书中的大部分学习算法可以理解成在整个数据集上获取经验。
数据集是指很多样本组成的集合，如\sec?的定义。
有时我们也将样本称为数据点。

<!-- % -- 101 -- -->

Iris（鸢尾花卉）数据集{cite?}是统计学家和机器学习研究者使用很久的数据集。
它是$150$个鸢尾花卉植物不同部分测量结果的集合。
每个单独的植物对应一个样本。
每个样本的特征是该植物不同部分的测量结果：萼片长度，萼片宽度，花瓣长度和花瓣宽度。
这个数据集记录了每个植物属于什么品种，其中共有三个不同的品种。

无监督学习算法训练含有很多特征的数据集，然后学习出这个数据集上有用的结构性质。
在深度学习中，我们通常要学习生成数据集的整个概率分布，显式地，比如密度估计，或是隐式地，比如合成或去噪。
还有一些其他类型的无监督学习任务，例如聚类，将数据集分成相似样本的集合。

监督学习算法训练含有很多特征的数据集，不过数据集中的样本都有一个标签或目标。
例如，Iris数据集注明了每个鸢尾花卉样本属于什么品种。
监督学习算法通过研究Iris数据集，学习如何根据测量结果将样本划分到三个不同品种。

大致说来，无监督学习涉及到观察随机向量$\RVx$的好几个样本，试图隐式或显式地学习出概率分布$p(\RVx)$，或者是该分布一些有意思的性质；
而监督学习包含观察随机向量$\RVx$及其相关联的值或向量$\RVy$，然后从$\RVx$预测$\RVy$，通常是估计$p(\RVy\mid\RVx)$。
术语监督源自这样一个视角，教员或者老师提供目标 $\RVy$给机器学习系统，指导其应该做什么。
在无监督学习中，没有教员或者老师，算法必须学会在没有指导的情况下让数据有意义。

无监督学习和监督学习不是严格定义的术语。
它们之间界线通常是模糊的。
大部分机器学习技术可以用于这两个任务。
例如，概率的链式法则表明对于向量$\RVx\in\SetR^n$，联合分布可以分解成
\begin{equation}
    p(\RVx) = \prod_{i=1}^n p(\RSx_i \mid \RSx_1,\dots,\RSx_{i-1}) .
\end{equation}
该分解意味着我们可以将其拆分成$n$个监督学习，来解决表面上的无监督学习 $p(\Vx)$。
另外，我们求解监督学习问题$p(y\mid\RVx)$时，也可以使用传统的无监督学习策略学习联合分布$p(\RVx,y)$，然后推断
\begin{equation}
    p(y\mid\RVx) = \frac{p(\RVx,y)}{\sum_{y'}p(\RVx,y')}.
\end{equation}
尽管无监督学习和监督学习并非完全没有交集的正式概念，它们确实有助于粗略分类我们研究机器学习算法时遇到的问题。
传统地，人们将回归，分类，或者结构化输出问题称为监督学习。
支持其他任务的密度估计通常被称为无监督学习。

<!-- % -- 102 -- -->

学习范式的其他变种也是有可能的。
例如，半监督学习中，一些样本有监督目标，但其他的没有。
在多实例学习中，样本的整个集合被标记为含有或者不含有该类的样本，但是集合中单独的样本是没有标记的。
参考{Kotzias2015}了解最近深度模型进行多实例学习的示例。

有些机器学习算法并不是训练于一个固定的数据集上。
例如，强化学习算法会和环境进行交互，所以学习系统和它的训练过程会有反馈回路。
这类算法超出了本书的范畴。
请参考{Sutton+Barto-98}或{Bertsekas+Tsitsiklis-book1996}了解强化学习相关知识，{Mnih2013}介绍了强化学习方向的深度学习方法。

大部分机器学习算法简单地训练于一个数据集上。
数据集可以用很多不同方式来表示。
在所有的情况下，数据集都是样本的集合，而样本是特征的集合。

表示数据集的常用方法是设计矩阵。
设计矩阵的每一行包含一个不同的样本。
每一列对应不同的特征。
例如，Iris数据集包含$150$个样本，每个样本有4个特征。
这意味着我们将该数据集表示成设计矩阵 $\MX\in\SetR^{150\times 4}$，其中$\MX_{i,1}$表示第$i$个植物的萼片长度，$\MX_{i,2}$表示第$i$个植物的萼片宽度，等等。
我们在本书中描述的大部分学习算法都是讲述它们是如何运行在设计矩阵数据集上的。

当然，将一个数据集表示成设计矩阵，必须是可以将每一个样本表示成向量，并且这些向量的大小相同。
这一点并非永远可能。
例如，你有不同宽度和高度的照片的集合，那么不同的照片将会包含不同数量的像素。
因此不是所有的照片都可以表示成相同长度的向量。
\sec?和\chap?将会介绍如何处理这类异质问题的不同类型。
在上述的这类情况下，我们不会将数据集表示成$m$行的矩阵，而是表示成$m$个元素的结合：$\{\Vx^{(1)},\Vx^{(2)},\dots,\Vx^{(m)}\}$。
这种表示方式并非意味着样本向量$\Vx^{(i)}$和$\Vx^{(j)}$有相同的大小。

<!-- % -- 103 -- -->

在监督学习中，样本包含一个标签或目标和一组特征。
例如，我们希望使用学习算法从照片中识别物体。
我们需要明确哪些物体会出现在每张照片中。
我们或许会用数字编码表示，如$0$表示人，$1$表示车，$2$表示猫，等等。
通常当工作在包含观测特征的设计矩阵 $\MX$的数据集时，我们也会提供一个标签向量$\Vy$，其中$y_i$表示样本 $i$的标签。

当然，有时标签可能不止一个数。
例如，如果我们想要训练语音模型转录整个句子，那么每个句子样本的标签是一个单词序列。

正如监督学习和无监督学习没有正式的定义，数据集或者经验也没有严格的区分。
这里介绍的结构涵盖了大多数情况，但始终有可能为新的应用设计出新的结构。

n## 实例：线性回归n
我们将机器学习算法定义为，通过经验以提高计算机程序在某些任务上性能的算法。
这个定义有点抽象。
为了使这个定义更具体点，我们展示一个简单的机器学习实例：线性回归。
当我们介绍更多有助于理解机器学习特性的概念时，我们会反复回顾这个实例。

顾名思义，线性回归解决回归问题。
换言之，我们的目标是建立一个系统，将向量$\Vx\in\SetR^n$作为输入，预测标量$y\in\SetR$作为输出。
线性回归的输出是其输入的线性函数。
让$\hat{y}$表示模型预测$y$应该取的值。
我们定义输出为
\begin{equation}
    \hat{y} = \Vw^\Tsp \Vx ,
\end{equation}
其中$\Vw\in\SetR^n$是参数向量。

参数是控制系统行为的值。
在这种情况下，$w_i$是系数，会和特征 $x_i$相乘之后全部相加起来。
我们可以将$\Vw$看作是一组决定每个特征如何影响预测的权重。
如果特征 $x_i$对应的权重$w_i$是正的，那么特征值增加，我们的预测值$\hat{y}$也会增加。
如果特征 $x_i$对应的权重$w_i$是负的，那么特征值减少，我们的预测值$\hat{y}$也会减少。
如果特征权重的大小很大，那么它对预测有很大的影响；如果特征权重的大小是零，那么它对预测没有影响。

<!-- % -- 104 -- -->

因此，我们可以定义任务$T$：通过输出$\hat{y} = \Vw^\Tsp \Vx$从$\Vx$预测$y$。
接下来我们需要定义性能度量，$P$。

假设我们有$m$个输入样本组成的设计矩阵，我们不用它来训练模型，而是评估模型性能如何。
我们也有每个样本对应的正确值$y$组成的回归目标向量。
因为这个数据集只是用来评估性能，我们称之为测试集。
我们将输入的设计矩阵记作$\MX^{\text{(test)}}$，回归目标向量记作$\Vy^{(\text{test})}$。

度量模型性能的一种方法是计算模型在测试集上的均方误差。
如果$\hat{\Vy}^{(\text{test})}$表示模型在测试集上的预测值，那么均方误差表示为：
\begin{equation}
    \text{MSE}_{\text{test}} = \frac{1}{m} \sum_i ( \hat{\Vy}^{(\text{test})} - \Vy^{(\text{test})})_i^2.
\end{equation}
直观上，当$\hat{\Vy}^{(\text{test})} = \Vy^{(\text{test})}$时，我们会发现误差降为$0$。
我们也可以表示为
\begin{equation}
    \text{MSE}_{\text{test}} = \frac{1}{m} \norm{ \hat{\Vy}^{(\text{test})} - \Vy^{(\text{test})}}_2^2,
\end{equation}
所以当预测值和目标值之间的欧几里得距离增加时，误差也会增加。

构建一个机器学习算法，我们需要设计一个算法，通过观察训练集$(\MX^{(\text{train})},\Vy^{(\text{train})})$获得经验，减少$\text{MSE}_{\text{test}}$以改进权重$\Vw$。
一种直观方式（我们将在后续的\sec?说明其合法性）是最小化训练集上的均方误差，$\text{MSE}_{\text{train}}$。

最小化$\text{MSE}_{\text{train}}$，我们可以简单地求解其导数为$\mathbf{0}$的情况：
\begin{equation}
\nabla_{\Vw} \text{MSE}_{\text{train}} = 0
\end{equation}
\begin{equation}
\Rightarrow \nabla_{\Vw} \frac{1}{m} \norm{ \hat{\Vy}^{(\text{train})} - \Vy^{(\text{train})}}_2^2 = 0
\end{equation}
\begin{equation}
\Rightarrow \frac{1}{m} \nabla_{\Vw} \norm{ \MX^{(\text{train})}\Vw - \Vy^{(\text{train})}}_2^2 = 0
\end{equation}
\begin{equation}
\Rightarrow \nabla_{\Vw} \left( \MX^{(\text{train})}\Vw - \Vy^{(\text{train})} \right)^\Tsp \left( \MX^{(\text{train})}\Vw - \Vy^{(\text{train})} \right) = 0
\end{equation}
\begin{equation}
\Rightarrow \nabla_{\Vw} \left( 
    \Vw^\Tsp \MX^{(\text{train})\Tsp}\MX^{(\text{train})}\Vw - 2\Vw^\Tsp\MX^{(\text{train})\Tsp} \Vy^{(\text{train})} + \Vy^{(\text{train})\Tsp}\Vy^{(\text{train})}  
  \right) = 0
\end{equation}
\begin{equation}
    \Rightarrow 2\MX^{(\text{train})\Tsp}\MX^{(\text{train})} \Vw  -
    2\MX^{(\text{train})\Tsp} \Vy^{(\text{train})}  = 0
\end{equation}
\begin{equation}
    \Rightarrow \Vw =  \left(\MX^{(\text{train})\Tsp}\MX^{(\text{train})}
     \right)^{-1} \MX^{(\text{train})\Tsp} \Vy^{(\text{train})}
\end{equation}

<!-- % -- 105 -- -->

通过\eqn?给出解的系统方程被称为正规方程。
计算\eqn?构成了一个简单的机器学习算法。
参看\fig?，线性回归算法在使用中的示例。

\begin{figure}[!htb]
\ifOpenSource
\centerline{\includegraphics{figure.pdf}}
\else
\centerline{\includegraphics{Chapter5/figures/linreg_color}}
\fi
\caption{一个线性回归问题，训练集包括了十个数据点，每个数据点包含了一个特征。因为只有一个特征，权重向量$\Vw$也只有一个要学习的参数$w_1$。（左）我们可以观察到线性回归学习$w_1$，从而使得直线$y=w_1x$能够尽量接近穿过所有的训练点。（右）标注的点表示由正规方程学习到的$w_1$的值，我们发现它可以最小化训练集上的均方误差。}
\end{figure}

值得注意的是，术语{线性回归}通常用来指稍微复杂一些，附加额外参数（截距项$b$）的模型。
在这个模型中，
\begin{equation}
    \hat{y} = \Vw^\Tsp \Vx + b,
\end{equation}
因此从参数到预测的映射仍是一个线性函数，而从特征到预测的映射是一个仿射函数。
如此扩展到仿射函数意味着模型预测的曲线仍然看起来像是一条直线，只是这条直线没必要经过原点。
不通过添加偏置参数$b$，我们仍然可以使用仅含权重的模型，但是$\Vx$需要增加一项永远为$1$的元素。
对应于额外$1$的权重起到了偏置参数的作用。
当我们在本书中提到仿射函数时，我们会经常使用术语"线性"。

<!-- % -- 106 -- -->

截距项$b$通常被称为仿射变换的\textbf{偏置}（bias）参数。
这个术语的命名源自该变换的输出在没有任何输入时会偏移$b$。
它和统计偏差中指代统计估计算法的某个量的期望估计偏离真实值的意思是不一样的。

线性回归当然是一个极其简单且有局限的学习算法，但是它提供了一个说明学习算法如何工作的例子。
在接下来的小节中，我们将会介绍一些设计学习算法的基本原则，并说明如何使用这些原则来构建更复杂的学习算法。

n# 容量、过拟合和欠拟合n
机器学习的主要挑战是我们的算法必须能够在先前未观测的新输入上表现良好，而不只是在训练集上效果好。
在先前未观测到的输入上表现良好的能力被称为泛化。

通常情况下，当我们训练机器学习模型时，我们可以访问训练集，在训练集上计算一些度量误差，被称为训练误差，并且我们会降低训练误差。
目前为止，我们讨论的是一个简单的优化问题。
机器学习和优化不同的地方在于，我们也希望泛化误差，也被称为测试误差，很低。
泛化误差被定义为新输入的误差期望。
这里，期望取值自我们期望系统在现实中从输入分布中采样得到的不同可能值。

通常，我们度量模型在训练集中分出来的测试集样本上的性能，来评估机器学习模型的泛化误差。

在我们的线性回归实例中，我们通过最小化训练误差来训练模型，
\begin{equation}
    \frac{1}{m^{(\text{train})}} \norm{\MX^{(\text{train})}\Vw - \Vy^{(\text{train})}}_2^2,
\end{equation}
但是我们真正关注的是测试误差，$\frac{1}{m^{(\text{test})}} \norm{\MX^{(\text{test})}\Vw - \Vy^{(\text{test})}}_2^2$。

<!-- % -- 107 -- -->

当我们只能观测到训练集时，我们如何才能影响测试集的性能呢？
统计学习理论提供了一些答案。
如果训练集和测试集的数据是任意收集的，那么我们能够做的确实很有限。
如果我们可以对训练集和测试集数据的收集方式有些假设，那么我们能够对算法做些改进。

训练集和测试集数据通过数据集上被称为数据生成过程的概率分布生成。
通常，我们会做一系列假设，被统称为独立同分布假设。
该假设是说，每个数据集中的样本都是彼此相互独立的，并且训练集和测试集是同分布的，其上数据采样自相同的分布。
这个假设使我们能够在单个样本上用概率分布描述数据生成过程。
然后相同的分布可以用来生成每一个训练样本和每一个测试样本。
我们将这个共享的潜在分布称为数据生成分布，记作$p_{\text{data}}$。
这个概率框架和独立同分布假设允许我们数学地研究训练误差和测试误差之间的关系。

我们能观察到训练误差和测试误差之间的直接联系是，随机模型训练误差的期望和该模型测试误差的期望是一样的。
假设我们有概率分布$p(\Vx,y)$，从中重复采样生成训练集和测试集。
对于某个固定的$\Vw$，训练集误差的期望恰好和测试集误差的期望一样，这是因为这两个期望的计算都是用相同的数据集生成过程。
这两种情况的唯一区别是数据集的名字不同。

当然，当我们使用机器学习算法时，我们不会提前固定参数，然后从数据集中采样。
我们会在训练集上采样，然后挑选参数去降低训练集误差，然后再在测试集上采样。
在这个过程中，测试误差期望会大于或等于训练误差期望。
以下是决定机器学习算法效果是否好的因素：
\begin{enumerate}
+ 降低训练误差
+ 缩小训练误差和测试误差的差距
\end{enumerate}

这两个因素对应机器学习的两个主要挑战：欠拟合和过拟合。
欠拟合发生于模型不能在训练集上获得足够低的误差。
过拟合发生于训练误差和和测试误差之间的差距太大。

<!-- % -- 108 -- -->

通过调整模型的容量，我们可以控制模型是否偏向于过拟合或者欠拟合。
通俗地，模型的容量是指其拟合各种函数的能力。
容量低的模型可能很难拟合训练集。
容量高的模型可能会过拟合，因为记住了不适用于测试集的训练集性质。

一种控制训练算法容量的方法是选择假设空间，即能够选为解决方案的学习算法函数集。
例如，线性回归函数将关于其输入的所有线性函数作为假设空间。
广义线性回归的假设空间包括多项式函数，而非仅有线性函数。
这样增加了模型的容量。

一次多项式提供了我们已经熟悉的线性回归模型，其预测如下：
\begin{equation}
    \hat{y} = b + wx.
\end{equation}
通过引入$x^2$作为线性回归模型的另一个特征，我们能够学习关于$x$的二次函数模型：
\begin{equation}
    \hat{y} = b + w_1x + w_2x^2.
\end{equation}
尽管该模型是\emph{输入}的二次函数，但输出仍是\emph{参数}的线性函数。
因此我们仍然可以用正规方程得到模型的闭解。
我们可以继续添加$x$的更高幂作为额外特征，例如下面的$9$次多项式：
\begin{equation}
    \hat{y} = b + \sum_{i=1}^9 w_i x^i.
\end{equation}

当机器学习算法的容量适合于所执行任务的复杂度和所提供数据的数量时，算法效果会最佳。
容量不足的模型不能解决复杂任务。
容量高的模型能够解决复杂的任务，但是当其容量高于任务时，有可能会过拟合。

\fig?展示了这个原理在使用中的情况。
我们比较了线性，二次和$9$次预测器拟合二次真实函数的效果。
线性函数无法刻画真实函数的曲率，所以欠拟合。
$9$次函数能够表示正确的函数，但是因为训练参数比训练样本还多， 所以它也能够表示无限多个刚好穿越训练样本点的很多其他函数。
我们不太可能从这很多不同的解中选出一个泛化良好的。
在这个问题中，二次模型非常符合任务的真实结构，因此它可以很好地泛化到新数据上。

\begin{figure}[!htb]
\ifOpenSource
\centerline{\includegraphics{figure.pdf}}
\else
\centerline{\includegraphics{Chapter5/figures/underfit_just_right_overfit_color}}
\fi
\caption{我们用三个模型拟合了这个训练集的样本。训练数据是通过随机抽取$x$然后用二次函数确定性地生成$y$来合成的。（左）用一个线性函数拟合数据会导致欠拟合－－－它无法捕捉数据中的曲率信息。（中）用二次函数拟合数据在未观察到的点上泛化得很好。这并不会导致明显的欠拟合或者过拟合。（右）一个$9$阶的多项式拟合数据会导致过拟合。在这里我们使用Moore-Penrose 伪逆来解这个欠定的正规方程。得出的解能够精确的穿过所有的训练点，但不幸的是我们无法提取有效的结构信息。在两个数据点之间它有一个真实的函数所不包含的深谷。在数据的左侧，它也会急剧增长，在这一区域真实的函数却是下降的。}
\end{figure}

<!-- % -- 109 -- -->

目前为止，我们探讨了通过改变输入特征的数目，和加入这些特征对应的参数，改变模型的容量。
事实上，还有很多方法可以改变模型的容量。
容量不仅取决于模型的选择。
模型规定了调整参数降低训练对象时，学习算法可以从哪些函数族中选择函数。
这被称为模型的表示容量。
在很多情况下，从这些函数中挑选出最优函数是非常困难的优化问题。
实际中，学习算法不会真的找到最优函数，而仅是找到一个可以降低训练误差很多的函数。
额外的限制因素，比如优化算法的不完美，意味着学习算法的有效容量可能小于模型族的表示容量。

<!-- % -- 110 -- -->

提高机器学习模型泛化的现代思想可以追溯到早在托勒密时期的哲学家的思想。
许多早期的学者提出一个简约原则，现在被广泛称为奥卡姆剃刀（c. 1287-1387）。
该原则指出，在同样能够解释已知观测现象的假设中，我们应该挑选"最简单"的那一个。
这个想法是在20世纪，由统计学习理论创始人提出来并精确化的{cite?}。

统计学习理论提供了量化模型容量的不同方法。
在这些中，最有名的是Vapnik-Chervonenkis维度。
VC维度量二元分类器的容量。
VC维定义为该分类器能够分类的训练样本的最大数目。
假设存在$m$个不同$\Vx$点的训练集，分类器可以任意地标记该$m$个不同的$\Vx$点，VC维被定义为$m$的最大可能值。

量化模型的容量使得统计学习理论可以进行量化预测。
统计学习理论中最重要的结论阐述了训练误差和泛化误差之间差异的上界随着模型容量增长而增长，但随着训练样本增多而下降{cite?}。
这些边界为机器学习算法可以有效解决问题提供了理论验证，但是它们很少应用于实际中的深度学习算法。
一部分原因是边界太松，另一部分原因是很难确定深度学习算法的容量。
确定深度学习模型容量的问题特别困难是由于有效容量受限于优化算法的能力。
对于深度学习中的一般非凸优化问题，我们只有很少的理论分析。

我们必须记住虽然更简单的函数更可能泛化（训练误差和测试误差的差距小），但我们仍然需要选择一个充分复杂的假设以达到低的训练误差。
通常，当模型容量上升时，训练误差会下降，直到其渐近最小可能误差（假设误差度量有最小值）。
通常，泛化误差是一个关于模型容量的U形曲线函数。
如\fig?所示。

\begin{figure}[!htb]
\ifOpenSource
\centerline{\includegraphics{figure.pdf}}
\else
\centerline{\includegraphics{Chapter5/figures/generalization_vs_capacity_color}}
\fi
\caption{容量和误差之间的典型关系。训练误差和测试误差表现得非常不同。在图的左端，训练误差和泛化误差都非常高。这是欠拟合期。当我们增加容量时，训练误差减小，但是训练误差和泛化误差之间的间距却不断扩大。最终，这个间距的大小超过了训练误差的下降，我们进入到了过拟合期，其中容量过大，超过了最佳容量。}
\end{figure}

<!-- % -- 111 -- -->

考虑任意高容量的极端情况，我们介绍非参数\emph{模型}的概念。
至此，我们只探讨过参数模型，例如线性回归。
参数模型学习到的函数在观测新数据前，参数是有限且固定的向量。
非参数模型没有这些限制。

有时，非参数模型仅是一些不能实际实现的理论抽象（比如搜索所有可能概率分布的算法）。
然而，我们也可以设计一些实用的非参数模型，使它们的复杂度和训练集大小有关。
这种算法的一个实例是最近邻回归。
不像线性回归有固定长度的向量作为权重，最近邻回归模型存储了训练集中所有的$\MX$和$\Vy$。
当需要为测试点$\Vx$分类时，模型会查询训练集中离该点最近的点，并返回相关的回归目标。
换言之，$\hat{y}=y_i$其中$i=\argmin \norm{\MX_{i,:}-\Vx}_2^2$。
该算法也可以扩展成$L^2$范数以外的距离度量，例如学习距离度量{cite?}。
如果该算法通过平均$\MX_{i,:}$中所有最近的向量对应的$y_i$来打破平局，那么该算法会在任意回归数据集上达到最小可能的训练误差（如果存在两个相同的输入对应不同的输出，那么训练误差可能会大于零）。

最后，我们也可以将参数学习算法嵌入另一个依所需增加参数数目的算法来创建非参数学习算法。
例如，我们可以想象一个算法，外层循环调整多项式的次数，内存循环通过线性回归学习模型。

<!-- % -- 112 -- -->

理想模型假设我们能够预先知道生成数据的真实概率分布。
然而这样的模型仍然会在很多问题上发生一些错误，因为分布中仍然会有一些噪扰。
在监督学习中，从$\Vx$到$y$的映射可能内在是随机的，或者$y$可能是包括$\Vx$在内还有其他变量的确定性函数。
从预先知道的真实分布$p(\Vx,y)$预测而出现的误差被称为贝叶斯误差。

训练误差和泛化误差会随训练集的大小发生变化。
泛化误差的期望不会随着训练样本数目的增加而增加。
对于非参数模型而言，更多的数据会得到更好的泛化能力，直到达到最佳可能的泛化误差。
任何模型容量小于最优容量的固定参数模型会渐近到大于贝叶斯误差的误差值。
如\fig?所示。
值得注意的是，具有最优容量的模型仍然有可能在训练误差和泛化误差之间存在很大的差距。
在这种情况下，我们可以通过收集更多的训练样本来缩小差距。

\begin{figure}[!htb]
\ifOpenSource
\centerline{\includegraphics{figure.pdf}}
\else
\centerline{\includegraphics{Chapter5/figures/training_size_grows}}
\fi
\caption{训练集大小对训练误差，测试误差以及最佳容量的影响。通过给一个$5$阶多项式添加适当大小的噪声，我们构造了一个合成的回归问题，生成单个测试集，然后生成一些不同尺寸的训练集。为了描述\%95置信区间的误差条，对于每一个尺寸，我们生成了$40$个不同的训练集。（上）两个不同的模型上训练集和测试集的MSE，一个二次模型，另一个模型的阶数通过最小化测试误差来选择。两个模型都是用闭式解来拟合。对于二次模型来说，当训练集增加时训练误差也随之增大。这是由于越大的数据集越难以拟合。同时，测试误差随之减小，因为关于训练数据的不正确的假设越来越少。二次模型的容量并不足以解决这个问题，所以它的测试误差趋近于一个较高的值。最佳容量点处的测试误差趋近于贝叶斯误差。训练误差可以低于贝叶斯误差，因为训练算法有能力记住训练集中特定的样本。当训练集趋向于无穷大时，任何固定容量的模型（在这里指的是二次模型）的训练误差都至少增至贝叶斯误差。（下）当训练集大小增大时，最佳容量（在这里是用最优多项式回归器的阶数衡量的）也会随之增大。最佳容量在达到足够捕捉模型复杂度之后就不再增长了。}
\end{figure}

n## 没有免费午餐定理n
学习理论表明机器学习算法能够从有限个训练集样本中很好地泛化。
这似乎违背一些基本的逻辑原则。
归纳推理，或是从一组有限的样本中推断一般的规则，在逻辑上不是很有效。
逻辑地推断一个规则去描述集合中的元素，我们必须具有集合中每个元素的信息。

在一定程度上，机器学习仅通过概率法则就可以避免这个问题，而无需使用纯逻辑推理整个确定性法则。
机器学习保证找到一个关注的\emph{大多数}样本\emph{可能}正确的规则。

不幸的是，即使这样也不能解决整个问题。
机器学习的没有免费午餐定理表明，在所有可能的数据生成分布上平均，每一个分类算法在未事先观测的点上都有相同的错误率。
换言之，在某种意义上，没有一个机器学习算法总是比其他的要好。
我们能够设想的最先进的算法和简单地将每一个点归为同一类的简单算法有着相同的平均性能（在所有可能的任务上）。

<!-- % -- 113 -- -->

幸运的是，这些结论仅在我们考虑所有可能的数据生成分布时才成立。
在现实世界的应用中，如果我们对遇到的概率分布进行假设的话，那么我们可以设计在这些分布上效果良好的学习算法。

这意味着机器学习研究的目标不是找一个通用学习算法或是绝对最好的学习算法。
反之，我们的目标是理解什么样的分布和人工智能获取经验的"真实世界"相关，什么样的学习算法在我们关注的数据生成分布上效果最好。

n## 正则化n
没有免费午餐定理暗示我们必须在特定任务上设计性能良好的机器学习算法。
我们建立一组学习算法的偏好来达到这个要求。
当这些偏好和我们希望算法解决的学习问题相吻合时，性能会更好。

至此，我们具体讨论修改学习算法的方法只有，通过增加或减少学习算法可选假设空间的函数来增加或减少模型的容量。
我们列举的一个具体实例是线性回归增加或减少多项式的次数。
目前为止讨论的观点都是过度简化的。

算法的效果不仅受影响于假设空间的函数数量，也取决于这些函数的具体形式。
我们已经讨论的学习算法，线性回归，具有包含其输入的线性函数集的假设空间。
对于输入和输出确实接近线性相关的问题，这些线性函数是很有用的。
对于完全非线性的问题它们不太有效。
例如，我们用线性回归，从$x$预测$\sin(x)$，效果不会好。
我们控制算法的性能，可以通过控制允许采样的函数种类的方式，也可以通过控制这些函数的数量的方式。

在假设空间中，相比于某一个学习算法，我们可能更偏好另一个学习算法。
这意味着两个函数都是符合条件的，但是我们更偏好其中一个。
只有非偏好函数比偏好函数在训练数据集上效果明显好很多时，我们才会考虑非偏好函数。

<!-- % -- 115 -- -->

例如，我们可以加入权重衰减来修改线性回归的训练标准。
带权重衰减的线性回归最小化，训练集上的均方误差和正则项的和$J(\Vw)$，偏好于平方$L^2$范数较小的权重。
具体如下：
\begin{equation}
    J(\Vw) = \text{MSE}_{\text{train}} + \lambda \Vw^\Tsp \Vw,
\end{equation}
其中$\lambda$是提前挑选的值，控制我们偏好小范数权重的程度。
当$\lambda =0$，我们没有任何偏好。
越大的$\lambda$偏好范数越小的权重。
最小化$J(\Vw)$可以看作是拟合训练数据和偏好小权重范数之间的权衡。
这会使得解决方案的斜率较小，或是将权重放在较少的特征上。
我们可以训练具有不同$\lambda$值的高次多项式，来举例说明如何通过权重衰减控制模型欠拟合或过拟合的趋势。
如\fig?所示。

\begin{figure}[!htb]
\ifOpenSource
\centerline{\includegraphics{figure.pdf}}
\else
\centerline{\includegraphics{Chapter5/figures/underfit_just_right_overfit_wd_color}}
\fi
\caption{我们使用高阶多项式回归模型来拟合图\?中训练样本。真实函数是二次的，但是在这里我们只使用$9$阶多项式。我们通过改变权重衰减的量来避免高阶模型的过拟合问题。（左）当$\lambda$非常大时，我们可以强迫模型学习到了一个没有斜率的函数。由于它只能表示一个常数函数，所以会导致欠拟合。（中）取一个适当的$\lambda$时，学习算法能够用一个正常的形状来恢复曲率。即使模型能够用更复杂的形状来来表示函数，权重衰减鼓励用一个带有更小参数的更简单的模型来描述它。（右）当权重衰减趋近于$0$（即，使用Moore-Penrose 伪逆来解这个带有最小正则化的欠定问题）时，这个$9$阶多项式会导致严重的过拟合，这和我们在图\?中看到的一样。}
\end{figure}

更一般地，正则化一个学习函数$f(\Vx;\Vtheta)$的模型，我们可以给代价函数添加被称为正则化项的惩罚。
在权重衰减的例子中，正则化项是$\Omega(\Vw) = \Vw^\Tsp \Vw$。在\chap?，我们将看到很多其他可能的正则化项。

<!-- % -- 116 -- -->

表示对函数的偏好是比增减假设空间的成员函数更一般的去控制模型容量的方法。
我们可以将去掉假设空间中的某个函数看作是对不赞成这个函数的无限偏好。

在我们权重衰减的示例中，通过在最小化的目标中额外增加一项，我们明确地表示了偏好权重较小的线性函数。
有很多其他方法隐式地或显式地表示对不同解决方法的偏好。
总而言之，这些不同的方法都被称为正则化。
\emph{正则化是指我们对学习算法所做的降低泛化误差而非训练误差的修改}。
正则化是机器学习领域的中心问题之一，能够和其重要性媲美的只有优化。

没有免费午餐定理已经清楚阐述了没有最优的学习算法，特别地，没有最优的正则化形式。
反之，我们必须挑选一个非常适合于我们要解决任务的正则形式。
深度学习中普遍的，特别是本书的，理念是大量任务（例如所有人类能做的智能任务）也许都可以使用非常通用的正则化项来有效解决。

n# 超参数和验证集n
大多数机器学习算法都有设置超参数，可以用来控制算法行为。
超参数的值不是通过学习算法本身学习出来的（尽管我们可以设计一个嵌套的学习过程，一个学习算法为另一个学习算法学出最优超参数）。

在\fig?所示的多项式回归实例中，有一个超参数：多项式的次数，作为\textbf{容量}超参数。
控制权重衰减程度的$\lambda$是另一个超参数。

有时一个设定被设为学习算法不用学习的超参数，是因为它太难优化了。
更多的情况是，该设定必须是超参数，因为它不适合在训练集上学习。
这适用于控制模型容量的所有超参数。
如果在训练集上学习超参数，这些超参数总是趋向于最大可能的模型容量，导致过拟合（参考\fig?）。
例如，相较低次多项式和正的权重衰减设定，更高次的多项式和权重衰减参数设定$\lambda=0$总能在训练集上更好地拟合。

<!-- % -- 117 -- -->

为了解决这个问题，我们需要训练算法观测不到的验证集样本。

早先我们讨论过和训练数据相同分布的样本组成的测试集可以用来估计学习过程完成之后的学习器的泛化误差。
其重点在于测试样本不能以任何形式参与到模型的选择，包括设定超参数。
基于这个原因，测试集中的样本不能用于验证集。
因此，我们总是从\emph{训练}数据中构建验证集。
特别地，我们将训练数据分成两个不相交的子集。
其中一个用于学习参数。
另一个作为验证集，用于估计训练中或训练后的泛化误差，更新超参数。
用于学习参数的数据子集通常仍被称为训练集，尽管这会和整个训练过程用到的更大的数据集相混。
用于挑选超参数的数据子集被称为验证集。
通常，$80\%$的训练数据用于训练，$20\%$用于验证。
由于验证集是用来"训练"超参数的，尽管验证集的误差通常会比训练集误差小，验证集会低估泛化误差。
所有超参数优化完成之后，泛化误差可能会通过测试集来估计。

在实际中，当相同的测试集已在很多年中重复地用于评估不同算法的性能，并且考虑学术界在该测试集上的各种尝试，我们最后可能也会对测试集有着乐观的估计。
基准会因之变得陈旧，而不能反映系统的真实性能。
值得庆幸的是，学术界往往会移到新的（通常会更具大更具挑战性的）基准数据集上。

n## 交叉验证n
将数据集分成固定的训练集和固定的测试集后，若测试集的误差很小，这将是有问题的。
一个小规模的测试集意味着平均测试误差估计的统计不确定性，使得很难判断算法$A$是否比算法$B$在给定的任务上做得更好。

<!-- % -- 118 -- -->

当数据集有十万计或者更多的样本时，这不会是一个严重的问题。
当数据集太小时，也有替代方法允许我们使用所有的样本估计平均测试误差，代价是增加了计算量。
这些过程是基于在原始数据上随机采样或分离出的不同数据集上重复训练和测试的想法。
最常见的是$k$-折交叉验证过程，如\alg?所示，将数据集分成$k$个不重合的子集。
测试误差可以估计为$k$次计算后的平均测试误差。
在第$i$次测试时，数据的第$i$个子集用于测试集，其他的数据用于训练集。
带来的一个问题是不存在平均误差方差的无偏估计{cite?}，但是我们通常会使用近似来解决。

n# 估计、偏差和方差n
统计领域为我们提供了很多工具用于实现机器学习目标，不仅可以解决训练集上的任务，还可以泛化。
基本的概念，例如参数估计，偏差和方差，对于形式化刻画泛化，欠拟合和过拟合都非常有帮助。

n## 点估计n
点估计试图为一些感兴趣的量提供单个"最优"预测。
一般地，感兴趣的量可以是单个参数，或是某些参数模型中的一个向量参数，例如\sec?线性回归中的权重，但是也有可能是整个函数。

为了区分参数估计和真实值，我们习惯表示参数$\Vtheta$的点估计为$\hat{\Vtheta}$。

让$\{\Vx^{(1)},\dots,\Vx^{(m)}\}$是$m$个独立同分布（i.i.d.）的数据点。
点估计或统计量是这些数据的任意函数：
\begin{equation}
    \hat{\Vtheta}_m = g(\Vx^{(1)}, \dots, \Vx^{(m)}) .
\end{equation}
这个定义不要求$g$返回一个接近真实值$\Vtheta$的值，或者$g$的值域恰好是$\Vtheta$的允许取值范围。
点估计的定义非常宽泛，给了估计量的设计者极大的灵活性。
虽然几乎所有的函数都可以称为估计量，但是一个好的估计量的输出会接近生成训练数据的真实参数$\Vtheta$。

<!-- % -- 119 -- -->

\begin{algorithm}
  \caption{$k$-折交叉验证算法。
当给定数据集$\SetD$ 对于简单的训练/测试或训练/验证分割而言太小难以产生泛化误差的准确估计时（因为在小的测试集上，$L$可能具有过高的方差），$k$-折交叉验证算法可以用于估计学习算法$A$的泛化误差。
数据集$\SetD$ 包含的元素是抽象的样本 $\Vz^{(i)}$ （对于第$i$个样本）， 在监督学习的情况代表（输入，目标）对$\Vz^{(i)} = (\Vx^{(i)}, y^{(i)})$ ，或者无监督学习的情况下仅用于输入$\Vz^{(i)} = \Vx^{(i)}$。
该算法返回$\SetD$中每个示例的误差向量$\Ve$，其均值是估计的泛化误差。
单个样本上的误差可用于计算平均值周围的置信区间（\eqn?）。
虽然这些置信区间在使用交叉验证之后不能很好地证明，但是通常的做法是只有当算法$A$误差的置信区间低于并且不与算法$B$的置信区间相交时，我们采声明算法$A$比算法$B$更好。}
\begin{algorithmic}
+[] \hspace*{-4.2mm}{\bf Define} {\tt KFoldXV}($\SetD,A,L,k$):
\REQUIRE $\SetD$为给定数据集，其中元素为 $\Vz^{(i)}$
\REQUIRE $A$ 为学习算法，可视为一个函数（使用数据集作为输入，输出一个学好的函数）
\REQUIRE $L$ 为损失函数，可视为来自学好的函数$f$，将样本 $\Vz^{(i)} \in \SetD$ 映射到标量$\in \SetR$的函数
\REQUIRE $k$为折数
\STATE 将 $\SetD$ 分为 $k$个互斥子集 $\SetD_i$，它们的并为$\SetD$
\FOR{$i$ from $1$ to $k$}
  \STATE $f_i = A(\SetD \backslash \SetD_i)$ 
  \FOR{$\Vz^{(j)}$ in $\SetD_i$}
    \STATE $e_j = L(f_i, \Vz^{(j)})$
  \ENDFOR
\ENDFOR
\STATE {\bf Return} $\Ve$
\end{algorithmic}
\end{algorithm}


现在，我们采取频率派在统计上的观点。
换言之，我们假设真实参数$\Vtheta$是固定但未知的，而点估计$\hat{\Vtheta}$是数据的函数。
由于数据是随机过程采样出来的，数据的任何函数都是随机的。
因此$\hat{\Vtheta}$是一个随机变量。

<!-- % -- 120 -- -->

点估计也可以指输入和目标变量之间关系的估计。
我们将这类点估计称为函数估计。

\textbf{函数估计}\quad 有时我们会关注函数估计（或函数近似）。
这时我们试图从输入向量$\Vx$预测变量$\Vy$。
我们假设有一个函数$f(\Vx)$表示$\Vy$和$\Vx$之间的近似关系。
例如，我们可能假设$\Vy = f(\Vx) + \Vepsilon$，其中$\Vepsilon$是$\Vy$中未能从$\Vx$预测的一部分。
在函数估计中，我们感兴趣的是用模型估计去近似$f$，或者估计$\hat{f}$。
函数估计和估计参数$\Vtheta$是一样的；函数估计$\hat{f}$是函数空间中的一个点估计。
线性回归实例（\sec?中讨论的）和多项式回归实例（\sec?中讨论的）都既可以解释为估计参数$\Vw$，又可以解释为估计从$\Vx$到$y$的函数映射$\hat{f}$。

现在我们回顾点估计最常研究的性质，并探讨这些性质说明了估计的什么性质。

n## 偏差n
估计的偏差被定义为：
\begin{equation}
    \text{bias}(\hat{\Vtheta}_m) = \SetE(\hat{\Vtheta}_m) - \Vtheta,
\end{equation}
其中期望作用在所有数据（看作是从随机变量采样得到的）上，$\Vtheta$是用于定义数据生成分布的$\Vtheta$的真实值。
如果$\text{bias}(\hat{\Vtheta}_m)=0$，那么估计量 $\hat{\Vtheta}_m$被称为是无偏，这意味着$\SetE(\hat{\Vtheta}_m) = \Vtheta$。
如果$\lim_{m\to\infty} \text{bias}(\hat{\Vtheta}_m)=0$，那么估计量 $\hat{\Vtheta}_m$称为是渐近无偏，这意味着$\lim_{m\to\infty} \SetE(\hat{\Vtheta}_m) = \Vtheta$。

<!-- % -- 121 -- -->

\textbf{实例：伯努利分布}\quad 
考虑一组服从均值为$\theta$的伯努利分布的独立同分布采样$\{x^{(1)}, \dots , x^{(m)}\}$：
\begin{equation}
    P(x^{(i)}; \theta) = \theta^{x^{(i)}} (1-\theta)^{(1 - x^{(i)})}.
\end{equation}
这个分布中参数$\theta$的常用估计量是训练样本的均值：
\begin{equation}
    \hat{\theta}_m = \frac{1}{m} \sum_{i=1}^m x^{(i)}.
\end{equation}
判断这个估计量是否有偏，我们将\eqn?代入\eqn?：
\begin{align}
    \text{bias}(\hat{\theta}_m)     &= \SetE[\hat{\theta}_m] - \theta  \\
            &= \SetE \left[ \frac{1}{m} \sum_{i=1}^m x^{(i)} \right] - \theta \\
            &= \frac{1}{m} \sum_{i=1}^m \SetE \left[x^{(i)} \right] - \theta \\
            &= \frac{1}{m} \sum_{i=1}^m \sum_{x^{(i)} = 0}^1 \left( x^{(i)} \theta^{x^{(i)}} (1-\theta)^{(1-x^{(i)})} \right) - \theta \\
            &= \frac{1}{m} \sum_{i=1}^m (\theta) - \theta \\
            &= \theta - \theta = 0
\end{align}

因为$\text{bias}(\hat{\theta})=0$，我们称估计$\hat{\theta}$是无偏的。

\textbf{实例：均值的高斯分布估计}\quad 
现在，考虑一组独立同分布的样本 $\{x^{(1)}, \dots , x^{(m)}\}$服从高斯分布$p(x^{(i)}) = \mathcal{N}(x^{(i)}; \mu, \sigma^2)$，其中$i\in\{1, \dots, m\}$。
回顾高斯概率密度函数如下：
\begin{equation}
    p(x^{(i)}; \mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left( -\frac{1}{2} \frac{(x^{(i)} - \mu)^2}{\sigma^2}  \right).
\end{equation}

